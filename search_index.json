[["index.html", "Extracting insights from dirty data - A use case of multisensory data from beehives Preface Acknowledgments", " Extracting insights from dirty data - A use case of multisensory data from beehives Alexandros Melemenidis 28 November 2020 Preface This is a slightly adjusted version of my Masters thesis in the study programme Big Data and Business Analytics at SRH Hochschule Heidelberg, submitted on 28 October and defended on 16 November 2020. The thesis was reviewed by Sven Garbade. Acknowledgments I would like to thank my project team colleague Diren Senger, my brother Andreas Melemenidis and my good friends Daniela Arru and Mario Morelli for their useful written comments, as well as Alexander Goncharskiy for volunteering as external reviewer of this thesis. Further I want to express my gratitude to Andr√© Lange, founder of the Rhein-Main local chapter of Correlaid e.V., for helping me find this project on short notice. "],["introduction.html", "Chapter 1 Introduction 1.1 Objective 1.2 Methodology", " Chapter 1 Introduction The European honey bee (apis mellifera) provides a significant contribution to agriculture in Germany and worldwide: the production of roughly 35% of globally consumed agricultural products relies on pollination by bees and other pollinators (Klein et al. (2007)). Besides that, bees produce honey, a product with up to 25 thousand tons of production and an even larger domestic consumption in Germany, according to the Federation of German Beekeepers (DIB). While the longer-term population trend of bee colonies has been positive in Germany, every year significant numbers of colonies do not survive the winter (Deutscher Imkerbund (2020)). A number of studies have identified as the largest, and statistically significant factors for the loss of colonies over the winter in particular mite pests and virus infections. Other factors, such as increased use of pesticides in nearby fields or global warming have been discussed in the literature with controversy: many critics of industrialized agriculture suggest that while modern pesticides are not directly lethal to bees when ingested via pollen, they might still have effects on the breeding of new bees and thus contribute to colony collapse at a later stage. A longitudinal study conducted since 2004 by a number of stakeholders in science and industry is the German Bee Monitoring Project (DeBiMo) (Genersch et al. (2010)), which collects high quality data from selected 120 beekeepers across Germany. This is done by means of regular surveys throughout the season as well as three annual inspections including detailed lab analyses. Up to now, the regular reports have identified as significant factors contributing to colony losses over the winter infestations with the Varroa mite, certain virus infections and old age of the queen, while there seems to be no indication of wrong beekeeping practice. The results obtained in this project might, however, be somewhat biased due to the selection of experienced beekeepers, which by definition lowers the possibility of wrong beekeeping practices. A wider survey of a different apicultural institute shows higher rates of colony losses over the winter than in DeBiMo (Klockgether and Hefner (2016)). A monitoring as in DeBiMo with only few inspections per year, however, only serves as a means of research, but provides little or no real-time support to the participating beekeepers to quickly react to possible mite pests or other problems. At the same time, a higher frequency of inspections, which involve physically opening the beehive, can cause intense stress to the bees and especially in the winter may be fatal for the colony. In recent years academia and industry have increasingly invested in finding less invasive solutions using Internet of Things (IoT) technologies, namely by installing various sensors within beehives for continuous observation and using machine learning methods to improve beekeeping practices. Bee Observer BOB, a Citizen Science project with a grant of the German Federal Ministry of Education and Research (BMBF) (BMBF-Internetredaktion (2019)), under project management of the University of Bremen Sensorbeuten - Cognitive Neuroinformatics (5/2/2020), is one project in this field. Being a Citizen Science project, BOB relies on support by volunteers, often via associations. In this context the stakeholders involved are the Hiveeyes project (The Hiveeyes Developers (10/2/2019)) and individual citizens for the development and implementation of the framework for the technical system of sensors, and CorrelAid CorrelAid (4/1/2020) for data analysis. The project further includes the participating beekeepers individually and via associations. The costs for the sensors as well as necessary spare parts for repairs are covered by the project, while the costs for electricity and internet connection have to be covered by the beekeepers themselves. The project grant of the BMBF is running out in December 2020, but the University of Bremen is currently exploring ways to continue the project afterwards. Work on the project has started in 2018 with the development of the sensors and since February 2019 data is continuously collected from beehives across Germany (and a few in other countries), providing information on temperature, humidity, air pressure and weight. Further, the participating beekeepers are storing the observations made during their regular inspections via a mobile application. The aim of CorrelAids involvement is to find out whether by using methods of machine learning one can detect outliers and anomalous trends and predict certain events in the development of the bee population. Successful models should then be implemented directly into the mobile app by the project team of the University of Bremen, so that beekeepers receive useful notifications to maintain colony health. 1.1 Objective The Internet of Things opens up enormous opportunities to research in general and apiology in particular: with growing amounts of data, researchers are able to get better insights into bee behavior and help beekeepers in their work, but also analyze the impact of external environmental changes on bees such as the use of pesticides. The open and voluntary nature of the Bee Observer project allows for a good inflow of data, but this comes at the cost of somewhat lower data quality: while the project team provides guidance on how to install the sensor kits, compliance with these guidelines and regular maintenance of the sensors cannot be ensured. Also, the sensors used in the project were selected for their relatively low costs, to keep entry barriers low for newcomers. These factors lead to a rather low data quality, expressed predominantly through lower than expected data volumes, when sensor fail to transmit data completely, or erroneous measurements, when sensor transmit data that is either outside the feasible sensor range or within the range, but implausible. This can happen when the sensor kits lose access to electricity or get damaged, which can happen e.g. when they overheat. As a second source of information there is a database on beekeeper inspections filled by the beekeepers via a mobile app, where, however, most fields are voluntary. To build a good basis for future bee research, in this thesis I will conduct an in-depth data quality analysis of the sensor data and propose appropriate data cleaning steps for the existing data on the one hand as well as monitoring solutions to improve the quality of future raw data. To keep the beekeepers active and engaged in the project I will also propose as an analytical use case a classification model to detect swarm events. 1.2 Methodology In the data quality assessment, the sensor and the inspections data will be analyzed with simple summary statistics and more detailed analyses, addressing seasonal patterns, missingness and correlation between variables. The sensor data will further be assessed under a data quality framework developed with a special focus on the Internet of Things (Cheng et al. (2018)). Based on the insights obtained from the analysis, rules to remove implausible sensor values and ideally impute them are defined. Further, suggestions to improve the design of the mobile app to record beekeeper inspections are made to improve the internal consistency of the data. As an analytical use case, a training dataset on swarming events is built, based on sensor data joined with information from on beekeeper inspections. Swarms should be detected in a timely manner, so that the beekeeper can react and move the colony into a new home instead of losing it. Different classification models are trained to detect swarming events, and the best is identified using standard performance metrics in a cross-validation exercise. The selected model should, however, also avoid too many false positives: too many unnecessary trips to the apiary may discourage the beekeepers from participating in the project. Afterwards, the model is tested on new unlabeled data collected during the swarming season to check how sensitive the model is. "],["literature.html", "Chapter 2 Literature 2.1 Short introduction to apiology 2.2 First steps in precision beekeeping 2.3 Useful methods of machine learning from other domains", " Chapter 2 Literature This section provides a basic introduction on the European honey bee, beekeeping and the first literature on the integration of Internet of things technology into beekeeping practice. Further, various machine learning methods appropriate for the analysis of sensor data in beekeeping are presented. 2.1 Short introduction to apiology The European honey bee is the most common species of honey bees. Honey bees are eusocial, that means they live in highly organized societies, called colonies, with different social castes and strong cooperation and division of labor (Wikipedia (2020)). A colony is formed by a single queen, a female with a fully developed reproductive tract, a large number of non-reproductive females, called worker bees, and a small proportion of fertile male drones. One colony can house tens of thousands of bees. Worker bees leave the hive during the day in spring and summer to forage nectar, water and pollen for the colony (thereby pollinating different plants) and convert it into honey and bee bread for immediate consumption or storage. In their earlier stages in life, workers nurse the brood within the hive, and build and maintain the hive using wax. The only purpose of the drones is to mate with and fertilize the queen, after which they immediately die. Individual workers and drones have a rather short life-span, but due to the continuous breeding by the queen, a colony can exist for multiple years. Communication within a colony happens via vibration, pheromones and dances. Given the high degree of social organization one can consider a bee colony a superorganism and reproduction of the colony (via swarming) rather than of individual bees is the significant unit to consider. In regions with temperate climate, such as Germany, the life cycle of a colony is typically as follows: in spring or early summer environmental conditions are favorable and the hive is filled with honey, leaving little space for new eggs. This will signal to the worker bees to nurse some eggs with royal jelly, which is higher in protein than honey, so that the eggs develop into queens. Normally, the pheromones of the queen would suppress the urge of worker bees to develop these queen cells, but with higher age the queen cannot produce enough of this scent. If the nursing of new queens is not suppressed, a swarm occurs: when the new queen hatches, the old queen leaves the hive with around half of the worker bees to found a new colony. After a few days of orientation, the young queen mates with multiple drones until she has collected enough sperm to start laying eggs. The number and pace of egg-laying depends on weather and resource availability. In Europe, queens typically stop breeding over the winter as workers cannot forage pollen and the colony is drawing on the food stored over the warmer periods. They will slowly resume breeding again in late winter when the days get longer. Before the winter the colony also expels the drones, as they would require too many resources. Honey bees have been domesticated for thousands of years, and with more industrialized agriculture across the world, the number of colonies globally has increased steadily. Nevertheless, in recent decades there have been increasing reports of colonies lost over the winter, which is a problem for beekeepers and farmers, whose crops may be dependent on pollination. A major cause behind this is Varroa Destructor, a mite species originally from Asia which became a problem in Europe in the 1970s (Rosenkranz, Aumeier, and Ziegelmann (2010)). Without technological solutions, the only way a beekeeper could monitor the health of his/her colonies was to conduct physical inspections of the hive. The process of inspections, however, can cause intense stress to the bees. Typically, a beekeeper lifts the cover of the hive and spreads smoke into the hive, which triggers an emergency behavior in the bees: in fear of a wildfire, they retreat into the inside of the hive and eat honey to prepare for a later evacuation. Due to this retreat it is now easier for the beekeeper to take out the individual frames of the beehive and inspect them one by one. During an inspection the carefully maintained micro-climate inside the hive is disturbed and will required substantial work by the colony to reestablish it after the inspection. During colder temperatures in winter, however, physical inspections would not be possible at all, as this could be fatal. To complement traditional methods of research, using manual inspections of beehives and laboratory analysis, but also to improve practical beekeeping, in recent years researches have worked on less invasive methods for monitoring bees, to be discussed in the following section. 2.2 First steps in precision beekeeping Interdisciplinary research on bees using IoT technology is a field still in development, yet expanding rapidly. There are numerous commercial initiatives offering full-service solutions for monitoring and analysis (Solutionbee (5/2/2020), Beewise (5/2/2020), Arnia - Remote Bee Hive Monitoring System (5/2/2020), Worlds Best Smart Beehive Monitoring System - Gobuzzr (5/2/2020), Innovative Beehive Monitoring System by Pollenity (4/22/2020)), yet also more academic work on the topic is getting published, with useful insights on the relationships between various environmental variables recorded via sensors and various events in a beehive: for example, before a colony starts swarming, one can observe a steady increase in temperature and humidity in the hive within the 20 minutes before the actual event, as many bees are warming up their muscles for flight at the same time (Zacepins et al. (2016), Anand et al. (2018)). Also, during swarming the queen bee is emitting a specific sound signal at a higher frequency (Anand et al. (2018)). Food consumption in non-foraging periods or the number of foraging workers can be estimated from weight changes (Zacepins et al. (2015)). Other use-cases for sensor data are simple alerts in case the hive gets too hot, too cold or too damp (Edwards Murphy, Magno, OLeary, et al. (2015), Markovic et al. (2016)) or in case the hive was knocked over by wind or a wild animal (Edwards Murphy, Magno, Whelan, et al. (2015)) using rule-based algorithms. In most cases, simple fixed decision rules are implemented and often based only on a single variable, but there have been first applications of machine-learning methods: in one case a decision-tree model classifies the current state of the colony to one of seven states (Edwards-Murphy et al. (2016)), in another application a two-class boosted decision-tree model predicts whether a colony will survive the winter or not (Dineva and Atanasova (2018)). Some proposed monitoring systems with analysis done directly in processing units close to the hive, so that less data needs to be transmitted via the internet, which however may limit computing power and restrict the toolset to simpler algorithms. 2.3 Useful methods of machine learning from other domains The main data of interest used in this project are continuous time series of numerical data. While there may be use cases for regression problems, for example to forecast the potential harvest of honey in a season given the data recorded at the hive level and external factors, the more obvious interest will lie in classification: what is the current status of the hive? Are the development conditions for the brood favorable? One well established method of classification is the logistic regression, where the probabilities of a specific event occurring are regressed on numerical predictors using an S-shaped logistic function (James et al. (2017)), with applications in many domains including economic research (Estrella and Hardouvelis (1991)). The logistic regression model is characterized by a linear relationship between the predictors and the logarithm of the odds of an event occurring. This property allows for a straightforward interpretation of the predictors model coefficients (in particular their signs) and their importance, but may make this model less appropriate in situations where relationships are non-linear. A more general method used for both regression and classification, with many applications across domains, are based on decision trees (Breiman et al. (1998)): here, the data are recursively segmented using randomly selected split variables so that the difference between segments is maximized and difference between observations within segments minimized. The model outcome is then the mode of each segment in terms of the categorical output variable in the case of a classification problem, or the means of the numerical output variable in the case of a regression problem. To avoid an overfitting of the tree models to the training data, the trees can be pruned, i.e. hyper-parameters can be set to limit the maximum depth of the tree in terms of the number of split nodes or to set a minimum number of data points contained in a node before it is split further. Later extensions of this principle, like Random Forests (Breiman (2001)) or Gradient Boosted Trees (Friedman (2001)) are built on combining and averaging multiple trees, rather than using just one, to further improve the generalization of the models to unseen data. Given the overall low number of observations on beekeeper inspections in the present dataset and thus labels to be used in classification models, it may be also useful to perform unsupervised learning methods for anomaly detection, classifying observations into normal and anomalous. Recurrent Auto-Encoders (Goodfellow, Bengio, and Courville (2016)) are a method of Deep Learning to analyze sequences of (numerical) data, in which the various transformation layers of the neural network are set in such a way that their inputs are recreated as good as possible. Depending on the distance between the original data and the output of the auto-encoder, the sequences receive an anomaly score and those beyond a certain threshold are classified as anomalies. This method has been successfully been applied for example in the domains of network security (Filonov, Lavrentyev, and Vorontsov (2016)) and maintenance of industrial machinery (Malhotra et al. (2016)). "],["data-profiling-and-assessment-of-data-quality.html", "Chapter 3 Data profiling and assessment of data quality 3.1 Sensor data 3.2 Inspections data 3.3 Apiary and hive metadata as a means to integrate data from external sources", " Chapter 3 Data profiling and assessment of data quality Bee Observer is based on two sources of internal data: the continuous flow of sensor data from beehives which is stored in an influxdb database (InfluxData (3/3/2020)), and the beekeepers records of their irregular inspections, which are stored in a MySQL database. Beyond the internal data, there may be merit in combining this information with data from other sources, for example meteorological data or geospatial data on agricultural practices nearby. In the context of the project I am able to retrieve sensor data from the influxdb independently, but due to privacy concerns, access to the inspections database is restricted to the project team at the University of Bremen who regularly provide database dumps to Correlaid project members. Data can be retrieved and analyzed locally, but the university also provides a dedicated server for RStudio with 12 CPU cores and 48GB RAM. The analyses in this thesis cover data collected from 21 February 2019 to 30 September 2020, but given the huge volume of raw sensor data due to the high frequency some detailed analysis of raw sensor data may sometimes be limited to some shorter sample periods. 3.1 Sensor data Since February 2019, monitored beehives are regularly storing data in an influxdb database system, a column-oriented system aimed at fast reading and writing of time series data. The data are organized in series or measurements tables for every string tag per beehive. The field variables only allow numerical or logical data. Besides requiring this structure, the system does not allow for further restrictions in the schema. As a consequence, the database will accept any numerical data for a given field. Data can be queried from the database using InfluxQL, a SQL-like query language which allows some basic aggregations and transformations, but for certain preprocessing required in the context of this project, such as conditional adjustments to fix erroneous sensor data or lags to model sequence classifiers, further processing in R is required.1 Every beehive transmits data on a number of variables, coming from three separate sensor units, as shown in figure 3.1 (taken from Senger et al. (2020)): first, there is one unit with six temperature sensors (Ds18s20 1-Wire Parasite-Power Digital Thermometer (5/9/2020)), measuring the temperature at five positions within the hive and once outside the hive. The second unit is a scale (Single Point Load Cell H40a (5/3/2020)), regularly measuring the weight of everything on it, i.e. the total of the hive, the bees, the pollen they foraged and honey they produced. Finally, there is another unit measuring humidity inside hive at the top, which also include another thermometer and a sensor for air pressure (Bme280 (5/7/2020)). All sensors are connected to a small programmable development board (Pycom (28.09.2020)), from which the data are sent to the influxdb server. The sensors used in the kits were selected to be cheap2 and easy to install for beekeepers, so that the entry barrier to participate in the project is low, but this may come at the cost of accuracy, also common to sensor data in general. Figure 3.1: Sensor set-up For an overview of the main variables available see table 3.1. Every observation contains a timestamp and the unique key of the specific beehive. In total there are 15 numeric variables , but the data availability for those not listed in the table is too low for meaningful statistical analysis3. There is some variation in the decimal precision across sensor kits, as this is set at the calibration by the beekeeper, but the values stated are a valid minimum for most. Table 3.1: Most frequent variables from sensors variable.names description type precision time timestamp of the observation in Universal Time Coordinated (UTC) POSIX date-time seconds key unique key of the beehive string - weight_kg total weight (= hive + bees + honey + food) numeric 0.001 kg h humidity at the top of the beehive numeric 0.01 % p air pressure at the top of the beehive numeric 1 hPa t temperature at the top of the beehive numeric 0.01 ¬∞C t_i_1  t_i_5 temperature inside: sensors 1 and 5 on the outside, 3 in the center and 2 and 4 in between numeric 0.01 ¬∞C t_o temperature outside numeric 0.01 ¬∞C At the time of writing, the influx database has accumulated hundreds of millions of raw observations, coming from 129 different beehives. However, the dataset lacks in completeness: weight measurements are recorded in most observations, suggesting that the scale is sending data at shorter time intervals than the other sensors, or is less likely to fail than the other sensor components. Next in frequency are temperatures from the thermometers and since these are six individual sensors, data availability is varying across them considerably. The three variables coming from the humidity sensor (relative humidity, temperature and air pressure), by contrast, have roughly equal numbers of observations, see figure 3.2. Figure 3.2: Number of non-missing observations in raw dataset The number of observations on other variables is negligible. Sensors record data broadly every five seconds (the middle half of the intervals for all variables is at that value), but sometimes it takes less or more time between two valid observations of a variable, see figure A.1 in the appendix. One has to note, however, that the various sensors may record their observations at different times in a non-synchronized way, making multivariate analysis difficult: in only around 60% of observations do we have non-missing entries for all our main variables of interest4. To better enable multivariate methods, it may be useful to aggregate observations to a common and regular sampling rate. Cheng et al. (2018) established a framework for data quality assessment in IoT, which can also be applied in this case, also to guide the strategy for cleaning. It provides objective indicators describing the volume of data relative to the theoretically possible volume, the share of complete observations and the share of correct observations5. The data quality indicators are based on a constant sampling rate and a common sampling period for all nodes of a sensor network. As the many sensor kits have been added to the Bee Observer project over time and since time intervals between observations are varying, these assumptions are quite strong in this case. By considering a short stable data sample, I lower the risk of including too many sensor kits with only partial data, and also save computing time6. As regards the sampling rate, it is actually preferable to reshape the dataset to a common sampling rate: one the one hand this will create regular time series which allows for various time series analysis methods, and second it will increase the share of usable observations. Figure 3.3 shows the data volume indicator, which is an average of the ratio of available observations to all possible observations in the common sampling period over all sensor kits: when aggregating the data to intervals of 5 seconds, which covered the majority of intervals of all variables of interest, data volume is at roughly 65%. When aggregating to lower frequency aggregates some gaps existing at higher frequencies are closed and the volume increases, reaching almost 75% at an interval of one minute and more than 80% at daily frequency. Figure 3.3: Data volume indicator at various sampling rates Aggregating the data to lower sampling rates will still not fix the issue of larger time gaps in the data: only a few beehives have transmitted data continuously over longer periods, and sensor outages over multiple days are not rare, see figure 3.4. For the application of many time series analysis methods, missing values are a problem and may have to be imputed. Figure 3.4: Heatmap of data availability Even when considering all hives together, the coverage of the period from March to May 2019 is low. Latest data until September 2020 show an increase in participation, nonetheless the problem of gaps in the data persisted, as can be seen in figure 3.5: while as of the second year of the project data availability is clearly trending upwards, the daily fluctuation in the number of sensor kits sending data suggests interruptions in transmission. Gaps can arise when a sensor itself or the Wi-Fi antenna fails, as the data are not stored in the sensor kit for a later attempt of retransmission. Even the maximum number of sensor kits sending data on a given day with around 50 is clearly below the total number of distinct sensor kits in the database of 129. Figure 3.5: Data availability over time The next indicator of data quality in sensor networks introduced by Cheng et al. (2018) is the data completeness indicator. This indicator is defined as the ratio of complete observations to the number of expected observations given the total sampling period and number of nodes in the network, in this case the sensor kits. I define a complete observation as one with non-missing values in the ten variables of interest. Figure 3.6 shows that at a sampling rate of 5 seconds the data set is around 40% complete, which can be increased to close to around 45% with a sampling rate of one observation per minute or lower. This low degree of completeness is due to a high share of beehives that do not have all sensors installed: out of 60 sensors transmitting data, only 36 send data on all variables of interest. Even at a low sampling rate such as daily, which is already not useful for a lot of real-time applications in beekeeping, less than half of observations are complete. Figure 3.6: Data completeness at various sampling rates The third data quality indicator by Cheng et al. (2018) that is relevant here relates to the correctness. The correctness indicator is defined as the ratio of observations for which the actual values deviate from the true value only by a small margin to all observations. As I do not have a way to know the true values of the physical phenomena measured in the beehives, I proxy the data correctness using the share of observations with values within the physical ranges as defined in the product specifications. Figure 3.7 shows that data correctness has a local peak at a sampling rate of 30 seconds at around 55% and goes down with lower sampling rates, again pointing at the issues of larger gaps in the data: as I aggregate to lower frequency intervals the share of correct values declines faster than overall observations. Even at daily frequency the ratio is not substantially higher at 57%. Figure 3.7: Data correctness (proxied) The low level of correctness is driven by the low completeness of the dataset: in order for an observation to be correct, all variables need to have non-missing values. Calculating the correctness indicator for the individual variables points at much higher rates (see figure A.2 in the appendix): even the variable with the lowest correctness (weight) has a share of valid values above 90%. The proxied correctness indicator has to be seen as an upper bound to actual data correctness, as the cheap sensors sometimes transmit data that is within the valid sensor ranges, but nonetheless not plausible. In particular, values are often persistent over longer periods of time. Given the high precision of the sensors and the continuous biological processes within the hive, changes of exactly zero are highly unlikely and probably represent sensor malfunctions. Within the beehives, the sensors can be exposed to extreme conditions for which they are not necessarily built: in case the beehive is not well-protected from direct sun, the sensors on the outside or at the top of the hive could easily overheat. Bees may build honeycombs around sensors with wax, which may block the functioning or also cause them to fail. Finally, exposure to organic acids during a treatment against Varroa mite may damage the sensors. 3.1.1 Single column analysis 3.1.1.1 Weight The total weight of the beehive is by far the main indicator of success or failure for the beekeeper: during spring the beekeeper should observe an increase in weight when the bees are foraging pollen and nectar. With knowledge about the weight of the empty hive and the weight fluctuations during a day the beekeeper can also estimate the population of the colony or the current pollen inflow. In the raw dataset the value distribution for the weight variable ranges from below negative 4 million on the bottom to more than 3 million. Given that there can be no negative weight, all negative values should be removed. Likewise, according to the product specifications, the measurement unit is kg and the weight sensor can only weigh up 300kg so values above 300 should also be removed. At the set-up, the beekeepers can calibrate the scale unit. In most cases, zero is set to the empty scale, but possibly some beekeepers may also set the zero value to the scale with the empty beehive on top7. Regarding upper limits of plausible weight values, one could further combine the data with information on the type of hive (see 3.3) and basic assumptions on the number and weight of bees in the colony. The initial cleaning of implausible weight levels reduces the number of observations by more than 10%. Now the distribution shows 99% of the technically feasible values lie in a range between 0kg and around 70kg, with a longer tail reaching until (exactly) 300 kg. As described earlier, there are considerable issues with sensor inaccuracy in the raw data, where sensors record extreme weight fluctuations by more than 10kg or even 20kg from one observation to the next, as seen in the thin grey lines of figure 3.8. From a logical point of view, in particular the temporary increases in weight appear questionable: the most likely possibility would be some wild animal climbing on the hive for some time, but this is unlikely to happen as often as indicated in the figure, thus pointing at erroneous measurements. To correct for possible mismeasurements, but also to create regular time series we can retrieve from the influxdb directly the median values for specified time-blocks, in the example shown we decided for five minutes. The solid red line in the same figure no longer shows that many extreme weight fluctuations. The remaining abrupt changes could all be explained by interactions of the beekeeper: temporary drops in weight would indicate a case when the beekeeper removes a number of frames from the hive to inspect the health of the colony, but otherwise does not interfere. A permanent abrupt increase in weight (typically by a few kg) would indicate an inspection with a feeding, while a permanent drop in weight would indicate the harvest of surplus honey. Figure 3.8: Time series of weight for selected beehive at different sampling rates Such a simple down-sampling to a lower frequency does, unfortunately, not always solve the problem: there remain implausible observations for other beehives, in particular abnormally high values. Looking closer at some of those cases, however, do not allow for a simple explanation: in cases when the scale jumps up, the observations following often indicate some fluctuation, often stronger than previously, see figure 3.9. Perhaps these are cases when an animal climbs onto the hive, but it could also indicate a temporary loss of calibration. Figure 3.9: Anomalous weight observations Also, the rate of change bringing the values to these new levels should be checked against the laws of physics: even during rather quick beekeeper inspections which should be the main cause of larger weight deviations, it will take the beekeeper some minutes to remove the frames from the hive and put them back in after inspection, as can be seen in figure A.3 in the appendix. Figure 3.10 illustrates that for most sensors, the weight measured changes from one observation to the next in a range between -10kg and +10kg per minute with the bulk of changes close to zero, while for a few sensors the range is much wider (from -10 tons to +10 tons per minute), indicating a general problem with the sensor. Figure 3.10: Distribution of weight changes Upon closer observation, two beehives appear to have their scales not correctly calibrated as they show massive daily fluctuations of up to 50kg which is clearly not possible (see figure A.4 in the appendix). Besides the impact of beekeeper inspections, the cleaned data indicate a reoccurring daily pattern during the foraging season: from sunset to sunrise the hive loses weight (~250 g) as the bees remain inside, but their bodies burn the consumed nutrients and foraged nectar and produced honey dries. Then at sunrise the weight drops to a daily minimum as the worker bees leave the hive to forage nectar and pollen and reaches a higher level again around sunset when all workers have returned. Depending on environmental conditions there may be a potential intermediate peak around noon, as can be seen in figure 3.11 for June 18th and 19th, 2019. Figure 3.11: Daily seasonality in weight This daily seasonal pattern is fairly strong: for most sensor kits with enough data the correlation between current weight and the weight one day before is strongly positive and - for most of those with at least 70 days of complete data - very close to 1. This is also true when considering shorter rolling windows, where the regularity is however interrupted whenever a beekeeper inspection is captured in the rolling window. With the start of the winter the bees stop foraging and the weight fluctuation ends and becomes a continuous slow decline in weight until the temperatures rise again and bees can start their next cycle. 3.1.1.2 Temperature Temperature is another important indicator for the well-being of a bee colony: for good breeding conditions, the temperature inside the hive close to the brood needs to be maintained around 34 ¬∞C. A consistently lower temperature may indicate that the colony is weakened and unable to maintain the microclimate necessary for breeding. A significantly higher temperature may indicate problems ventilating the hive, which may also lead to a colony collapse. Similar to the weight data, also the raw observations for the various temperature variables have wide distributions going far beyond the product specifications of the sensors (for the thermometer unit from -55¬∞C to +125¬∞C and for the humidity unit from -40¬∞C to +85¬∞C), in particular for those from the thermometer unit. After removing those implausible values, one can observe that while for all sensors there are values towards the limits of the technical sensor range, but that the bulk of observations is concentrated in a rather narrow range from around 0¬∞C to +50¬∞C inside and -10¬∞C to +40¬∞C outside, indicating that the values beyond these ranges are also more likely to be erroneous measurements. These, however, appear to occur quite often and over longer time periods, so that they may also be present when considering median values for five-minute blocks, see figure 3.12: over a course of four days the temperature readings of various thermometer units drop to levels close to 0¬∞C and stay there for longer periods of time before returning back to normal. At a data precision of 0.01 ¬∞C, within a small space with thousands of living bees (or outside, subject to the elements), longer periods of exactly zero change is very unlikely and suggest an issue with the sensors. This phenomenon of values frozen for long appears to be linked to the five sensors of the temperature unit inside (t_i_1  t_i_5). For a number of sensor kits a high share of observations show changes of zero, even at aggregations for a lower sampling rate, although this is not always at necessarily problematic levels. The temperature measurements from the humidity unit at the top of the hive as well as those from the outside sensor suffer less from this phenomenon, but nonetheless contain outliers. The temperature outliers for all sensors are often, but not always, located before or after a period without transmission. Figure 3.12: Temperature time series for selected beehive To monitor the health of the colony, in particular the health of the brood, it would be useful to obtain temperature measurements from close to the brood. The additional placement of cables in a hive, however, makes beekeeping more difficult. To interfere with beekeeping as little as possible, the designers of the system suggested to install the sensors in between the frames so that they can be removed without any issue (Hiverize (5/16/2020)). With this design based on the box rather than the bees, it is not possible to ensure to have a specific proximity to the brood. One would assume that the sensor in the middle, t_i_3, would be closest to the brood as one would expect the colony to maintain the brood at a maximum distance to the outside, to keep temperature at a sufficient level. This is, however, not the case for all hives and not for the whole time period as the distribution of brood cells within the hive may change over time, see figure 3.138. Figure 3.13: Location of highest temperature for selected beehive During the summer period, a stability in temperature around the optimum for brood development, as described in the literature (Zacepins et al. (2016)), can be observed for a lot of hives in this dataset, but this is not maintained over the winter. For the wider range of hives, all temperature data underlies considerable day-night fluctuations and a general seasonal pattern over the year. 3.1.1.3 Humidity Humidity is another important parameter for the health of a bee colony, in particular for the development of the brood: Doull (1976) showed that there is an ideal range of relative humidity in the brood nest that allows larvae to develop well, while under too dry conditions the eggs may shrivel or if the bees do hatch, they may not be fully developed. More recent works using sensors (Human, Nicolson, and Dietemann (2006)) revealed distinct day and night patterns and somewhat different humidity levels at different locations inside the beehive. Researchers are still unclear as to whether humidity is actively regulated by the bees or passively as a side effect of thermoregulation: for example. when the nest temperature becomes too warm bees spread droplets of water on the comb and fan their wings to make the water evaporate and cool the temperature, this will at the same time raise humidity. According to the product specifications, the sensor measures relative humidity, that is the saturation of air with water vapor relative to its maximum capacity at a given temperature, measured in percent. By definition, the values have to be within a range from 0% to 100%. The raw dataset does, however, contain both negative values as well as very large positive values, which need to be cleaned. Humidity is also underlying a strong daily seasonality, during the foraging season humidity drops from sunrise onwards, becoming relatively dry as workers leave the hive, and increases again when they return: overnight the bees evaporate body heat and the foraged nectar, which to a large proportion is water, dries. In terms of data quality, long gaps in the data when no data (or at least no data within the sensor range) are transmitted are frequent across time and beehives, whereas the problem of frozen sensors, as illustrated earlier with temperature, does not occur so much. By contrast, besides the daily patterns, the relative humidity within the hive is very volatile, see figure 3.14, and much more so than for weight and temperature. Figure 3.14: Daily seasonality and general volatility of relative humidity With the start of the winter the daily fluctuation becomes less and the general level of relative humidity is higher, see figure 3.15. The positive correlation with the humidity level of the previous day is more stable than for weight, but somewhat lower. Figure 3.15: Humidity fluctuation for a selected beehive with long history 3.1.1.4 Air pressure So far there was no mentioning of the air pressure in previous work on precision beekeeping, but the humidity sensor unit does record this information, so discarding it may be premature: Air pressure is an environmental factor and could correlate with weather conditions, which ultimately would also affect bee behavior. According to the product specifications the sensor can measure air pressure in a range from 300 to 1100 hPa. As most beehives in the dataset are located in Germany, one could also generally exclude values that would imply the beehive is located higher than the Zugspitze, i.e. values below around 650 hPa. The remaining observations then stay in a quite narrow range. Over time there is cyclical variation in air pressure, which is more weekly rather than daily and in general not really predictable. Pressure values are very persistent, given the low precision of the sensor at 1 hPa, leading to step-like time series as shown in figure 3.16. Figure 3.16: Air pressure over time for a selected bee hive It appears unlikely that bee behavior is reflected in changes in air pressure as measured by the sensor given the difference in seasonality with the other variables, but the data on air pressure may still be useful as a more precise indicator for weather conditions than meteorological data that needs to be first retrieved from other sources and which will likely have a lower frequency. 3.1.2 Initial cleaning In order to have good results in any analysis, the sensor data need to be cleaned from values that do not represent actual developments within the beehive, but rather sensor failures. At the same time, the cleaning should not be too computationally expensive so that the cleaning could also run online. As a first step we should remove observations clearly outside the sensor range and at the same time reduce volatility and improve completeness of the dataset by filtering and down-sampling to lower time intervals. This can already be implemented at the level of the influxdb database using continuous queries as shown in the code chunk below for the chosen interval of one minute using medians. The sampling rate of one minute is chosen to capture volatile developments such as swarms, which occur within only few minutes, as shown later. CREATE CONTINUOUS QUERY &quot;enforce_range_and_downsample_weight&quot; ON &quot;bee_data&quot; RESAMPLE EVERY 5m FOR 10m BEGIN SELECT median(&quot;weight_kg&quot;) AS &quot;weight_kg&quot; INTO &quot;bee_data&quot;.&quot;autogen&quot;.&quot;downsampled_sensors&quot; FROM &quot;sensors&quot; WHERE &quot;weight_kg&quot; &gt;= 0 AND &quot;weight_kg&quot; &lt;= 300 GROUP BY &quot;key&quot;, time(1m) END Based on the analysis in the previous sub-section, it appears to be a good idea to remove observations which show a faster rate of change than could be explained by natural changes in the bee hive, the environment or due to beekeeper interventions and thus indicate sensor failure. Further, observations representing zero change should be removed. While they occur quite often, and the observation levels of most of them are within plausible ranges, some form of interpolation method to more gradual changes may improve the predictive properties of models. The next code chunk shows an example of a simple R implementation on how to remove these types of observations using Tidyverse packages (Wickham et al. (2019)), which runs with a satisfactory performance on a local machine on a table of around 6 million observations with 10 columns at a 1-minute sampling rate: it is a simple loop that for each sensor-kit and variable computes the rate of change between two subsequent observations, filters out zero changes and extreme changes and repeats until there are no problematic changes left. thresholds &lt;- c(h = 10, weight_kg = 16, p = 2, t_o = 0.75, t = 6, t_i_1 = 6, t_i_2 = 6, t_i_3 = 6, t_i_4 = 6, t_i_5 = 6) clean_zero_and_extreme_change &lt;- data_within_sensor_range %&gt;% group_by(key) %&gt;% group_modify(~ { # FOR EACH VARIABLE FOR EACH SENSOR KIT individual_dfs &lt;- map(vars, function(variable) { temp &lt;- .x[, c(&quot;time&quot;, variable)] %&gt;% rename(v = variable) %&gt;% # REMOVE MISSING VALUES AND COMPUTE GROWTH PER MINUTE RELATIVE TO PREVIOUS OBSERVATION drop_na() %&gt;% mutate(derivative = (v - lag(v))/as.numeric(time - lag(time), units = &quot;mins&quot;)) # FILTER OUT ZERO CHANGES AND CHANGES BEYOND THE DEFINED THRESHOLD, RECOMPUTE CHANGES AND REPEAT UNTIL THERE ARE NO MORE EXTREME CHANGES while(max(abs(temp$derivative), na.rm = T) &gt; thresholds[variable]) { temp &lt;- temp %&gt;% filter((abs(derivative) &lt;= thresholds[variable] &amp; derivative != 0) | is.na(derivative)) %&gt;% mutate(derivative = (v - lag(v))/as.numeric(time - lag(time), units = &quot;mins&quot;)) } temp &lt;- temp %&gt;% select(-derivative) names(temp) &lt;- c(&quot;time&quot;, variable) return(temp) }) # COMBINE VARIABLES TO ONE DATAFRAME reduce(individual_dfs, full_join, by = c(&quot;time&quot;)) }) The thresholds selected for declaring changes as implausible is different across variables and are described in table 3.2. Given the extreme movements in weight - but partially also temperature - during beekeeper inspections, the thresholds for these variables need to be somewhat higher. The cleaning is thus only able to remove the most extreme implausible observations, as shown in the red lines in figure 3.17. Table 3.2: Thresholds for variable fluctuations variable.names description threshold.for.changes weight_kg total weight 16 kg / minute h humidity at the top of the beehive 10 % / minute p air pressure at the top of the beehive 2 hPa / minute t temperature at the top of the beehive 6¬∞C / minute t_i_1  t_i_5 temperature inside: sensors 1 and 5 on the outside, 3 in the center and 2 and 4 in between 6¬∞C / minute t_o temperature outside 0.75¬∞C / minute Figure 3.17: Effect of simple cleaning algorithm While removing or correcting values may improve data quality, ideally sensor failures should not occur in the first place. To quickly react to wrong calibration or emerging defects of some sensors, monitoring tools for beekeepers as well as for the project team may help remedy these issues. A project team colleague has implemented an R script to identify longer sequences of missing values by sensor kit and variable which was already implemented in a dashboard solution for the project team, see figure 3.18. Simpler summaries on time elapsed between subsequent observations, or the number of observations outside the technical sensor range within a given time interval could also be implemented already at the level of the database using continuous queries and be visualized in near real-time. Figure 3.18: Interactive visualization of missing values By removing more observations, correctness may improve, but possibly at the cost of data volume and completeness. For certain lengths of data gaps, it may thus be useful to interpolate missing values based on available data for other variables. As a basis of understanding the relationships between the variables, the next section analyses the correlations between them. 3.1.3 Multi-column analysis To analyze the relationship among the ten variables of interest, we restrict ourselves to a smaller subset of 34 bee hives which report observations on all variables of interest at multiple points in time, resulting in about 7.1 million observations since February 2019. After removing values outside the technically feasible ranges as well as steep changes and zero changes, we end up with slightly below 7 million observations containing information on at least one variable. As this step removed a lot of zero change values in between valid observations, it is useful to refill shorter gaps using simple interpolation techniques9. I do this with the using the imputeTS package (Moritz and Bartz-Beielstein (2017)). This brings the sample again closer to the original number of observations. The data quality analysis at the beginning of this chapter already indicated that the data are very incomplete overall, but this is not just the case for bee hives with missing sensors and never report complete observations, but also for those that do have complete observations. Following the methodology of Kuhn and Johnson (2019), the so-called upset plot in figure 3.19 shows that after the interpolation of shorter gaps around one sixth of the observations are missing data from the temperature unit, whereas this is somewhat less of an issue for the scale and the humidity unit (bar chart panel on the left-hand side). Missingness tends to be clustered at the technical unit: in more than 600,000 observations all three variables from the humidity unit are missing and in around 300,000 cases the six sensors of the temperature unit did not report valid observations (tallest two bars on the top panel bar chart). In around 250,000 observations data from the scale are missing. Besides observations with no data at all (excluded from the chart), other combinations of missing variables or instances of only one variable missing are less frequent. Figure 3.19: Upset plot of missingness after initial cleaning Given the large issue of missingness from the temperature unit it would be useful to analyze whether missing values for temperature occur at specific values for the non-missing variables. Looking at the distribution of values for relative humidity and outside temperature between observations with the value for the central temperature sensor missing and those with data, there is a tendency for missingness to occur at lower outside temperatures and higher humidity (see figure A.6 and figure A.5 in the appendix). Looking at the last valid observations before a data gap compared with normal valid observations confirms this picture, see figure A.7 in the appendix. Thus, beekeepers as well as the project team should probably pay more attention on sensor maintenance during spring and autumn, when temperatures are lower, but inspections are still possible without endangering the bees too much. As a next step we should analyze how the variables are related when not missing, as strong correlations may be useful for the imputation of missing values over longer periods. Given the higher volatility of the humidity data, we transform it to centered 5-minute moving averages. While the relationships differ somewhat between sensor kits, the general pattern seen everywhere is a positive correlation between the temperature sensors inside the hive, in particular of those next to each other. The temperature at the top of the hive is somewhat less positively correlated with the temperatures at the center, but more strongly with the outside temperature, see figure 3.20. Looking at all observations together, there is a clear negative correlation between humidity and temperature (in particular at the same sensor at the top of the hive), but this does not hold across all sensor kits, perhaps due to differences in the seasons covered. Figure 3.20: Correlations among temperature variables 3.2 Inspections data Further to installing the sensor kits, beekeepers participating in Bee Observer can log their inspections in a web application suitable to work on smartphones. Screenshots of all app menus can be found in the appendix (figure A.10). The information logged enters a MySQL database that is organized in rows per aspect of the inspection, instead of one row per inspection. This results in a somewhat odd mixed structure in which different data types are combined in one numeric column value, which, depending on the category ID, may represent either a Boolean value, a number, a qualitative value on an ordered Likert scale or the option selected from a dropdown list menu. The only mandatory variables that need to be provided is the date and time of the inspection, whether or not the colony was fed, a score on how gentle the bees react to the inspection, how much flight activity they show and how the hive was inspected (fully, i.e. by opening the box and removing frames, just by looking through the flight hole or something in between). All other fields are optional to not discourage beekeepers from participating in the project. For an overview of the schema see table 3.3. Table 3.3: Inspections database schema variable.name description type inspection_id unique identifier of the inspection integer created_at date of submission POSIX date-time deleted_at time of deletion, NULL otherwise POSIX date-time impression overall impression (from the inspection in general)  three smileys integer attention does the hive require attention? Boolean notes textual notes on the inspection string reminder textual notes to be sent along with the calendar reminder for the next inspection text category_id identifier for the input field/variable integer value value numeric category_input_id identifier for the input type integer name textual description of the category input ID string translation textual description of the category ID  not unique! string hive_id unique key of the hive  one hive can contain multiple sensor kits integer key unique key of the sensor kit (as in sensor dataset) string For the time period since February 2019 the database contains 18495 rows, but since some were test entries which were later deleted, this can be reduced to only 16239 data entries coming from 1099 inspections. However, a large number of records were prepared by beekeepers who do not have sensors installed in their hives or have not yet entered this information in the app. Excluding also those observations without a reference to a sensor key, the sample is further reduced to 6927 observations from 417 inspections. Given that most fields are optional, there is considerable difference in the number of observations, see figure A.12 in the appendix. In around half of the inspections the beekeepers indicate whether the bees are foraging pollen, and whether frames have been added or removed. Data availability is also acceptable regarding the stocks of honey and pollen, the status of the brood and whether the colony is infested with Varroa mite. The most available data type is logical. For the considered time period, the number of inspections per hive also varies considerably. More than half of all inspections were recorded for ten hives. For the hives with more than one logged inspection the interval between inspections is typically less than weekly, but for sometimes up to a month can pass until the next inspection. Given the design of the mobile app, there is a logical functional dependence between related fields in most cases: for example, the beekeeper can only enter the number of frames that were added or removed during an inspection if he/she checked Yes in the parent box Inserted/Removed Frames. However, there are number of cases were the app allows for internally inconsistent responses, which should be corrected in a future version: for example, it is not physically possible to add or remove frames if the type of inspection was by only observing the flight entrance or just tilting the cover. Yet, two inspections can be found in the dataset where supposedly the cover was only tilted, but it was recorded that frames were added or removed. The categories blocks Swarming and Swarm prevention are handled separately, which can lead to records where the destruction of queen cells as a swarm prevention method was recorded, but at the same time there was either no status reported on the building of queen cells or it was recorded as not occurring. In the current dataset this inconsistency can be observed in 30 cases. Further, some fields are perhaps not clear to the beekeepers. The counters for adding or removing frames allow for negative numbers, thus the designers expected the users to record negative numbers for removed frames and positive numbers for added frames but this may not be how beekeepers have understood this. Currently the value distribution for the seven types of frames is rather balanced with values both on the positive and negative side, so from that point of view this appears fine. When combining sensor data from the scale with inspection data, however, there are cases of inspections with a reported net addition of frames in which the overall weight has dropped (see figure 44), which could indicate a wrong reporting10. In any case, the menu should be designed somewhat clearer, perhaps with an immediate response that a positive number is interpreted as an addition while a negative is a removal. When using information from the inspection database as labels for classification models, one has to consider that there is some uncertainty surrounding the timestamp of the inspections. By default, the time recorded is the time when the inspection menu was opened, which should typically be after the inspection was completed. If the beekeeper choses to manipulate the date this may result in a timing closer to the change in weight, but in case the time is not remembered correctly, it may as well be recorded earlier than the change in weight. A mis-recording could potentially explain the position of the fourth inspection in figure 3.21. As most states of or events within the colony, however, likely take longer than just a few minutes, the information about the colony entered in the inspection log is probably valid for a longer time before (or around) the time of the inspection. Figure 3.21: Time series of weight with inspections For the available inconsistent records, the data can be corrected directly if applicable, or the beekeepers could be contacted by the Bee Observer project team to ask about the inspection. As regards the time stamp, a method of anomaly detection might be well-placed to detect at least the strong movements in weight which are unlikely to be caused by the bees themselves. 3.3 Apiary and hive metadata as a means to integrate data from external sources In order to record an inspection, beekeepers first need to create their apiary and its individual hives in the database. Only two variables are mandatory: the chosen name of the apiary and the type of hive. The optional variables at the apiary level relate to the geolocation, while at the hive level the beekeepers can specify the number of layers used in the hive for brood and honey and the number of frames per layer. Finally, specifics about the queen of the hive can be specified, such as the race, the birthdate and whether her wings have been clipped. The menus of the app are shown in figure A.9 in the appendix. This metadata can provide useful information for the analysis of the sensor data. First of all, the mandatory information on the hive type can help in cleaning erroneous sensor data for weight more precisely. As the various hives are made from different materials are differently sized and may have their capacity used to different degrees, the lower threshold for the valid weight observations can vary significantly. Second, with available geolocation data, one is able to calculate the position of the sun at a given time, and retrieve other external data that may be useful in explaining developments in a bee colony. As there have been increasing cases of colony theft across Germany (Meidel (9/4/2020)) the general terms of service of the Bee Observer project included a data protection clause limiting the use of geolocation data only at a lower precision. Specifically, we have coordinates rounded at one decimal, which amounts to an uncertainty of up to 11km. Within the inspections dataset there are currently 66 sensor kits at various locations in Germany (mostly the western L√§nder and Berlin) and the Netherlands, as shown in figure 3.22, and two in the USA. Figure 3.22: Location of hives 3.3.1 Determining the sun level The European Honey Bee has a diurnal cycle. Foraging worker bees cannot see well in the dark and research has also shown that they require a certain amount of rest (i.e. sleep) to function well during the day (Kaiser and Steiner-Kaiser (1983)). As a consequence, the activity within a hive will look different during day and night. Given the astrological cycle of the Earth around the sun, these daily cycles will change over the year, with days being longest and the suns position highest at the end of June at summer solstice. Afterwards the days become shorter and the suns position lower, reaching their trough at the end of December at winter solstice and so on. To get cleaner signals over the general trend of a colony it would be useful remove the changing daily seasonality from the trend. Time-series methods such as Seasonal and Trend decomposition using Loess (STL) (Cleveland et al. (1990)) are able to deal with slowly changing seasonal patterns, but require complete sequences of data, which is not always given in this case with sometimes long periods of sensor outages. Thus, it may be preferable to directly determine the cycles based on the position of the sun. The position of the sun can be calculated with a mathematical formula using the coordinates and the date-time information. The small uncertainty surrounding the exact location in this case should be negligible. The package suncalc (Thieurmel and Elmarhraoui (2019)) provides a simple R implementation for these computations. Figure 3.23 for a selected hive during June 2020 illustrates this daily cycle well: around sunrise, the worker bees leave the hive (which may result in further decrease in weight), but throughout the day bring nectar and pollen to the hive, leading to a peak in weight around sunset. Overnight the hive loses weight at a stable rate, as the stored honey dries and the bees bodies burn energy and evaporate humidity. Figure 3.23: Sun position and weight for a selected hive during the foraging period 3.3.2 Meteorological data Not only the day-night cycle can affect bee behavior, also meteorological phenomena can have an impact. While bees can still fly when it rains, flying during rain or even just mist is more difficult: water can accumulate on the bees body and thus increase its weight. Heavy raindrops can push a bee down and throw it off its course. Thus, during longer periods of rainfall bees typically do not go foraging and stay in the hive, as shown in figure 3.24, where a rainy week is interrupting a period of weight increase in the foraging season. The figure also shows one more potential issue of sensor quality: the sudden drop in weight around 1 May during the rainiest time could be a sign of a sensor malfunction due to the scale becoming wet or at least too damp. The only beekeeper inspection during the period shown was recorded at this beehive on 18 April, with a much lower weight fluctuation. The German Weather Service (DWD) provides regularly updated data on precipitation at various intervals from multiple weather stations throughout Germany, with the frequency going as high as per minute, reported from almost a thousand stations. Data on air temperature and the dew point are available at hourly frequency from around 500 stations. The datasets can be conveniently accessed from R using the rdwd package (Boessenkool (2020)). Due to the uncertainty surrounding the exact location of the hive, it may be useful to obtain data from multiple stations in the vicinity and combine them. Even in case the exact location was known, heavy rainfall at the nearest weather station may still be a very localized event that potentially would not affect the monitored colony at all. Figure 3.24: Foraging behavior and precipitation Joining the obscured hive locations with the location of the weather stations, one can see that within a radius of 20km around the hive there is at least one weather station for all hives in Germany. In case of precipitation data at one-minute frequency the majority of hives have two and more weather stations nearby (see figure A.13 in the appendix). Air pressure recorded by the sensor in the hive is typically lower during stronger rainfalls at a nearby station (see figure 3.25) and thus could be an indicator of rain, but a passing low-pressure area does not necessarily mean it indeed rained and if yes, at the same time. For the majority of hives with available location and pressure data, the correlation coefficient between pressure and cumulative daily rainfall ranges between -0.2 and -0.4 Thus, to control for the effect of rainfall on bee behavior in a model, using actual meteorological data should be preferable over just the pressure data from the sensor kits themselves. Figure 3.25: Cumulative daily precipitation amounts and air pressure in the hive Temperature data from an official source can also serve as a cross-check of the data quality for the outside temperature sensor. In figure 3.26, for example, one can observe a close co-movement between the sensor data and the measurements from surrounding weather stations until April 2020, when the sensor data significantly deviate upwards, likely due to sensor failure. Figure 3.26: Outside temperature measured from sensor vs. official source While at present, the DWD does not offer weather forecasts in an easily accessible format, this may be added in the future, allowing for potential use cases like suggestions for the ideal timing of inspections (before it rains). 3.3.3 Phenological data Around 400 DWD weather stations also report on the stage of the lifecycle of various plants in the vicinity on a daily basis. Among these plants there are also eight11 which have been identified as useful for pollinators (Pflanzen f√ºr Best√§uber (n.d.)), as a source for pollen, nectar or both. Only for few plants the observers report both the beginning and end of the blossoming, while for most of the plants, only the start is recorded. Exploratory data analysis shows that one can indeed map the most productive time of the bee colony to the status of the environment. Assuming a consistent duration of the blossoming period of six weeks, figure 3.27 shows higher weight gains in periods when multiple plants are blossoming. Relevant seem to be in particular dandelion, sweet cherry, rapeseed and apple (starting to blossom around April to May). Figure 3.27: Joining weight and phenological data Knowledge about the state of the surrounding flora could be useful in focusing the models and detection algorithms to this crucial period and notify the beekeepers if there is no significant weight gain. Influxdb is under continuous development: in the current beta branch, the system offers an alternative query language (flux) which already implements some of the described missing features, which would allow for a more streamlined data analysis pipeline going forward. However, some simple preprocessing such as filtering and down-sampling to a lower frequency can already be implemented using so-called continuous queries in the version currently available to the project. At the time of writing the purchase price of all components together was just above 100 Euro. The other variables include the calibration weight of the scale, however only with few observations, and the strength of the Wi-Fi signal. This is a proxy, as influxQL does not allow for comparisons of numerical time series with NULL: in this column-oriented database system, if there is no value, there is no entry at all. The ratio is computed as the number of observations where the values of all our variables of interest are not equal to a specific value, divided by the number of observations for weight, the variable with the most observations. The framework also contains indicators on the volatility and timeliness of the data However, as I have no physical access to any sensor kit, I cannot evaluate the timeliness of the data and thus focus in this section only on the first three indicators. The month of July 2020 is chosen, as only six new sensor kits are added throughout the month, compared to more than a hundred existing ones. This information is unfortunately not stored and is thus not available for a further cleaning to reduce the variable to pure developments in the weight of the bees and foraged food. The temperature measured at the humidity sensor unit t, is excluded from this analysis: due to its position at the top of the hive it is more strongly correlated with the outside temperature and can thus easily reach high values during the summer, above those required in the brood nest. Given the different volatility of the variables we chose different gaps: humidity 1 hour; temperatures 10 minutes; weight 5 minutes; pressure 4 hours. For this thesis a linear interpolation was chosen. The linear interpolation has the advantage that it can be implanted at the level influx of the influxdb and would not be able to create values outside the plausible sensor ranges again. This is of course based on the simplified assumption that frames have the same weight when they are added to the hive as when they are removed and have the same weight across types of frames. Also, the changing of frames needs to be seen together with other beekeeping actions that influence weight, such as feeding and honey harvest. Apple, sweet cherry, forsythia, dandelion, horse-chestnut, goat willow, corn and rapeseed. "],["use-cases-for-machine-learning-methods.html", "Chapter 4 Use cases for machine learning methods 4.1 Supervised swarm detection 4.2 Other use cases for supervised methods 4.3 Unsupervised anomaly detection", " Chapter 4 Use cases for machine learning methods As described before in section 2.2, the first implementations of sensor technologies in apiculture were often using simple decision rules to support the beekeepers. Examples for these simple rules are: Temperature increases inside the hive by more than 1¬∞C compared to 30 minutes ago over multiple consecutive minutes: the colony is swarming (Zacepins et al. (2016)). Lowest temperature inside the hive &lt; 5¬∞C or highest temperature &gt; 36¬∞C: unfavorable climate  alert sent to the beekeeper (Markovic et al. (2016)) (Edwards Murphy, Magno, OLeary, et al. (2015)). These studies were, however, conducted at rather small scale (e.g. four hives for Bayir and Albayrak (2016), one hive over limited time for Edwards Murphy, Magno, OLeary, et al. (2015)) and under close supervision of the researchers to maintain a good data quality. While according to the project design of Bee Observer all hives in the project should have the same sensor setup and thus the same variables available, the data quality analysis in section 3.1 has shown that data availability is fluctuating over time, and due to the lack of control by the project team, some beekeepers have not even installed all three sensor components in their hives. Further, as shown earlier in figure 3.13, the center of the brood nest may move over longer periods, thus making it difficult to deduct the bee health state from the same temperature sensor. Lastly, previous research was based on data from hives in broadly the same geographical area, whereas in Bee Observer the data are sent from hives across Germany and even some other countries. Thus, colonies might be affected by different environmental influences in their regions which may affect their behavior, requiring adjustments to static rules. Instead of programming alert systems based on static rules it would be rather preferable to use flexible methods of machine learning to learn relationships between the variables that influence or are influenced by the behavior of the bees inside the hive. 4.1 Supervised swarm detection One of the most obvious use cases of machine learning in beekeeping is to detect swarm events: If a swarm goes unnoticed, the part of the colony that left may either abandon the apiary or even die, and even if caught in time, both halves of the former colony are now weakened and are producing less honey over the remainder of the year. A mechanical tool to allow the beekeeper to quickly react, catch the swarm and give it a new hive will thus be of economic value. Between April and June 2020, 13 swarm events were recorded in the beekeeping apps. Unfortunately, in only six cases were the sensor kits also active during the event. Thus, for the training of a classification model that could detect swarm events and warn the beekeeper in time, the sample size is still quite limited. Nonetheless, also in this limited sample12, we can make similar observations as Anand et al. (2018), who could only observe one event, see figure 4.1. Starting around half an hour before departure until the point when the swarming is concluded, a steady and significant increase in temperature is recorded in the center of the hive (but also at the other temperature sensors) as well as, albeit to a smaller degree, an increase in relative humidity. This happens as the part of the colony that is about to leave the hive is warming up their muscles for flying. Using the rough patterns observed in terms of changes in weight, temperature and humidity as well as the level of temperature, I was able to identify three more swarming events in the sensor data, which were not at all or not correctly entered in the dataset on inspections, raising the sample of sensor keys with swarms to eight. These three swarms were confirmed by the project colleagues as they contacted the respective beekeepers. Figure 4.1: Characteristics of a swarm event The observed drops in weight also help us estimate the total weight of a bee colony: assuming around half the colony leaves the hive during the swarming, a full colony will weigh between 7kg and 10kg. Further, these observations also teach us about the length of the process and consequently at what maximum frequency we should analyze the data, at least for the detection of swarms: leaving the hive took between five and eight minutes for the five colonies observed, thus if one would aggregate the data too much, say into five-minute medians, the distinct temperature and humidity increases may be masked, and the steep, but nonetheless gradual, weight decreases would appear too abrupt. At least for the use case of swarm detection, a sampling rate of 1 minute seems appropriate. 4.1.1 Training a classification model With the previous observations we learned that swarm events are characterized by a sequence of developments: temperature and humidity increase first, then, when the bees start departing and the weight measured on the scale starts decreasing, also humidity begins decreasing again. Given that warm air rises, the peak in temperature is only reached when the departure of the bees has been concluded, before it decreases again with some delay. Thus, to classify a swarm, it makes sense to not only consider level and growth rates of the variables at a given time, but also what happened in the minutes before. To this end we calculate 10-minute differences for humidity, weight and the three inner temperature sensors and the upper temperature sensor as well as the first ten lags for each of the growth rates. Following Ziegler, Dettli, and Thommen (2019), who reported that swarming typically occurs during the day, we also add as predictor the time of day in seconds13. The analysis in section 3.1.1.2 showed that the central temperature sensors characterize well the developments in the brood nest, but across beehives and over time the center of the nest with the highest temperatures may be located closer to different sensors. Thus, instead of considering each thermometer reading inside the hive, I aggregate the information to the maximum of the three sensors, reducing the number of variables. As some of the sequences do not have complete observations on all temperature sensors and model training requires complete observations, this transformation will also improve the size the dataset. Also, due to the higher volatility of humidity compared to the other variables, its level and growth rates are less useful as swarm predictors. Thus, instead of the raw humidity data, a centered five-minute moving average is chosen for the training dataset. Finally, it is clear that the many lagged growth rates will be very closely related to one another and may likely not carry a lot of additional predictive power for a model. I thus apply an additional high correlation filter (removing variables correlated with others by more than \\(\\rho = 0.9\\)), which reduces the set of predictors to 13, namely the four sensor series, their 10-minute differences and their 10-minute differences lagged by ten minutes, as well as the time of day. Using additional predictors such as weather data as presented in section 3.3.2 could additionally be considered, but as the geocoordinates are not available for all beehives, this might result in a further reduction of the training dataset. Further, in the analyzed period it is likely that environmental conditions outside should in most cases be supportive of a swarm event as it should be sufficiently warm during the day and less likely to rain between April and July compared with the rest of the year. This should however be investigated next year with more and better data available. For the labels, we define as TRUE for the binary variable swarm the observations five minutes before and after the observation at the beginning of the departure (T=0 in figure 4.1) and all other observations as FALSE. As one of the eight sensor kits has none of the temperature sensors reporting during the event, in the training dataset we include only seven swarm sequences plus the twenty minutes before and after, respectively. Further, to train the model not to mislabel quick weight drops during inspections as swarms, we include one hour of data during inspections and another hour of normal daily behavior. Excluding observations with missing values (in one case of a swarm the sensors were switched back on just shortly before) we end up with a quite imbalanced training dataset of 518 observations, of which 77 are labelled as swarms. Given the class imbalance of the dataset, I add as a final pre-processing step an up-sampling using the SMOTE algorithm (Chawla et al. (2002)) which creates synthetic observations for swarms using the k-nearest neighbors of actual swarm observations. A first attempt of modelling a classifier using logistic regression fails to converge even on the significantly reduced set of variables. After reducing dimensionality further to ten predictors using the greedy Wilks algorithm for feature selection, the model yields acceptable results on the training dataset, but fails on new data: For the other observations in the sample, which likely do not exhibit swarms, the predicted probabilities of a swarm occurring often reach very high levels, in particular during inspections. As a logistic model implies that the log odds increase in a linear relation to the predictors, the model interprets any strong decrease in weight as a sign of a swarm occurring, while in reality the weight decrease is bound to be the weight of around half a bee colony (i.e. something in the range of 4-5kg) and the temperature does not increase endlessly. Thus, a model allowing for non-linearities is likely a better option. I estimate a Random Forest model with the ranger package (Wright and Ziegler (2017)) using the default hyper-parameters (1000 trees, number of variables used for splitting mtry = 3  sqrt(13), minimum node size of 10) and test its accuracy in ten-fold cross-validation in folds with similar class relations. The accuracy in training is high with above 97% and an area under the ROC curve of over 99%. Given the high frequency of the data at one-minute intervals, a low relative false positive rate may still mean thousands of wrong notifications to the beekeeper, which we would want to avoid. Figure 4.2: Swarm probabilities in training set The visualization of the predicted swarm probabilities in the training set in figure 4.2 shows when the random forest and the logistic regression models react to actual swarm events. To check the usefulness of our models, I also apply the trained models on the remaining unlabeled observations from the time period between April and July 2020. As no other swarms were entered in the dataset on inspections, one should not expect too many swarms to have occurred, and thus the models should classify the vast majority of observations as not belonging to swarm events. Otherwise we might end up with a model that could send notifications based on false positives, which should be avoided, as beekeepers may lose interest in participating in the project if the app causes them unnecessary trips to the apiary. For the Random Forest model this condition is met, as probabilities remain generally low for the new data. Only in very few cases - likely due to sensor failure - the model (falsely) predicts a swarm with high probability of around 75%, which still is a considerable improvement compared with the logistic regression model, which reacts very strongly very often, see the example shown in figure 4.3. Figure 4.3: Applying trained models on new data An issue of the trained Random Forest model is its dependence on complete observations. As our data is often incomplete, either due to the sensors not sending data or sending erroneous data that are then removed by the cleaning algorithm, there are many observations where the full model would not produce predictions at all. Based on the analysis of missingness shown in figure 19, the most frequent cause of incomplete data is one sensor component failing completely. Indeed, in training the logistic regression and random forest models before, one case of a swarming event was actually not included, as it had no records from the thermometer unit during the event. Thus, to complement the above model using data from all three sensor components, we further train three more Random Forest models with default hyperparameters for cases where only two of the three components are active and three more with only one component active. All models are estimated using the same complete observations as the full model. Figure 4.4 shows that reducing the number of predictors does not have a significant negative effect on model performance: in fact, the model without variables based on weight achieves a higher accuracy and specificity than the model with data from all sensor components. Overall, the accuracy is quite high across models and in a rather narrow range between 96% and 98%. Figure 4.4: Model performance depending on number of used sensor components For specificity, the metric explaining the share of non-swarm observations that are correctly predicted, the variation is somewhat wider: while the models with the highest overall accuracy also have higher specificities between 84% and 88%, which is also achieved by the model using only thermometer data, the models using only the scale, the humidity sensor or both achieve an average specificity between 74% and 80%. All estimated models could still be improved using hyper-parameter tuning. Also, other model types such as Boosted Trees could be explored. However, given the small training dataset and the overall low data quality, a too extensive modelling approach appears premature at this stage and should be targeted for late 2021, when hopefully data quality has improved and more swarms were recorded. 4.1.2 Importance of swarm prevention One reason behind the overall low count of swarms in the data so far is that the beekeepers actively try to prevent swarming. One popular method of swarm prevention is introducing a new queen annually, or at least every two years, to make sure that enough pheromones are emitted to keep the worker bees from developing queen cells. Other measures include clipping the queens wings or destroying new queen cells once discovered. It may thus be of merit to also look not only into hives where swarms have happened to provide timely alerts to the beekeeper to catch the swarm and provide a new home, but also analyze those hives in which the beekeepers observe the first signs of the colonys urge to swarm, namely by developing queen cells or at least building the required structure, a fake queen cell (Spieln√§pfchen in German). In the case of the eight sensor kits with recorded swarm events, only two had recorded observations of building of queen cells before the swarming event. In one case, however, the beekeeper cut out the queen cells (mentioned in the qualitative notes) and in the last inspection value for this variable before the swarming event, around one month earlier, the value was set to FALSE, thus the beekeeper likely assumed to have successfully suppressed the bees urge to swarm. While in the currently available data there are not enough observations for useful analysis, looking ahead it may be useful to include in the set of predictors of any detection model a dummy on whether building of queen cells was observed during inspections in the recent time and on types of swarm prevention methods applied, if any, but this depends on the completeness and accuracy on the side of the beekeepers. 4.2 Other use cases for supervised methods At the current stage, the dataset on inspections is quite small not allowing for sound analysis combining sensor and inspection data, but going forward a number of other use cases come to mind: Estimate risk of colony loss: do the sensor data for colonies lost over the winter differ from those that survive? Can dangerous levels or trends be detected early enough for the beekeeper to intervene before the hibernation? An application of a supervised approach using boosted decision trees was presented by (Dineva und Atanasova, 2018). In the current dataset only one reported colony loss fell within a period with recorded sensor data which is not enough for statistical inference. Detection of Varroa mite pests or other diseases: can sensor data show a significant effect of a Varroa mite infestation or a spread of the Deformed Wing Virus? E.g., would less bees leave the hive for foraging, leading to a smaller weight fluctuation and less pollen and honey inflow or would the bees inside have more difficulties maintaining the microclimate within the hive? An early detection of diseases and thus an early treatment may improve the health of the colony. In the currently available data, only six hives with sensor data recorded 22 cases of Varroa infestation, while ten more hives with sensor data recorded negative observations on this issue. Estimation of colony size and food reserves: based on the weight and its daily fluctuation during the foraging period one could estimate the number of bees in the colony and thus their food demand. Regression methods could help suggest an ideal amount of honey to be harvested and/or the right amount of supplement feeding that would not lead to starvation of the colony. 4.3 Unsupervised anomaly detection Given the rare occurrence of inspections and the generally low size of the inspection dataset compared to the millions of sensor observations it may also be useful to gain insights from unsupervised methods, classifying the data into normal and anomalous. The approach chosen by Davidson et al. (2020) was to use a method of Deep Learning, namely Recurrent Auto-Encoders, to classify 60-minute sequences of consecutive data from beehives with heterogenous sensor set-ups, and were able to detect anomalies that were due to beekeeper inspections, but also swarms. The training of Neural Networks, however, requires complete sequences of data, which can rarely be achieved in the currently available dataset. Within Bee Observer, the project team also worked on a methods of anomaly detection, to be presented at an upcoming conference (Senger et al. (2020)): on the simpler side. the distance of the observed values to the moving median of the last five minutes for one or multiple variables of interest are classified using a statistical test for outliers. More advanced methods exploit the stationarity and seasonality of the variables: the variables are modelled using uni- or multivariate Autoregressive Integrated Moving Average (ARIMA) models and the outlier test is then applied to the model residuals. Tested on a number of selected, mostly complete sequences of data, the moving median as well as some advanced methods are able to identify a substantial share of observations as anomalies that are within a close distance of an inspection recorded in the beekeeper app. Afterwards the anomalous observations are clustered together based on their timestamps (acknowledging the longer duration of inspections), and an agent-based model assesses the likelihood that the anomaly could be due to an inspection based on the variables such as the time since the last inspection or the weather conditions. The anomalies detected by the unsupervised models would afterwards provide a good starting point for further analysis using supervised methods. One more swarm was registered, which was however not used in the later dataset to train the model: in this case the beekeeper was present when the colony started swarming and initiated a full inspection at the time of departure. Thus, effects of the swarm and the external intervention overlap and may likely affected the predictive power of a model negatively. As this analysis was limited to the normal swarming season between April and July, a further predictor for the time in the year was not deemed necessary. When more swarm data becomes available in future data collections, allowing for more balanced training sets, it may be useful to include (non-swarm) observations outside the swarming season and also include the day in the year as a predictor. "],["conclusion-and-outlook.html", "Chapter 5 Conclusion and Outlook", " Chapter 5 Conclusion and Outlook This thesis presented various analyses on data collected within Bee Observer, a citizen science project to help beekeepers, especially hobbyists, in their beekeeping practice and at the same time contribute to bee research by building a large dataset. The project is aimed at openness, through its technical framework using relatively cheap sensors that are easily installed and can be repaired by the beekeepers themselves, a mobile app for inspections with largely voluntary fields and little central oversight by the project team. This setup contributed to a larger sample compared to datasets shown in previous work in the young research field of precision beekeeping, but came at the cost of lower data quality: besides widespread gaps in data transmission, there are large numbers of observations showing other types of sensor failure. A simple first round of data cleaning steps was proposed which will improve data volume, completeness and correctness and can already be implemented at the database level. Also, to deal with some inconsistencies in the inspections data, a few changes in the app design were proposed. These steps will improve data quality in the future. To further improve the quality of the data currently available and make it useful for analytical applications, a further cleaning step was proposed to remove sensor freezes and extreme changes, which helped cleaning in particular temperature data. Possible important environmental drivers of bee behavior were discussed, for which external data is available and can be joined with the sensor data using the knowledge about the (rough) location of the beehive. As an analytical use case a Random Forest classification model was proposed for the detection of swarm events, using features exclusively based on the sensor data. The model achieved a high overall accuracy and an acceptable specificity on the training set. Tested on other unlabeled data from the same period, this model also (falsely) classified only few observations as swarms, signaling that an implementation would not have resulted in a high number of false alerts that may be bad for participation of beekeepers in the project. Given the issue of low data completeness, alternative models are trained using only a subset of the sensor components. As their performance is not substantially lower than the full model, the project team may also consider leaner sensor set-ups in the future. Looking ahead, further research should be done on the dangers to bee health, especially on whether sensors can register abnormal trends during Varroa mite pests early on, so that beekeepers can treat their colonies in time, potentially more effectively and less harmful for the bees. In terms of data quality, further quality checks based on external sources data for outside temperature and humidity could be implemented. "],["additional-charts.html", "A Additional charts", " A Additional charts For most subsequent observations, the interval is five seconds - the IQR is a line rather than a box in the below chart. Sometimes, however, the intervals are shorter or (much) longer. Figure A.1: Time gaps between non-missing observations The low level of overall data correctness is largely driven by the by the high occurrence of incomplete data. Looking at the proxied correctness for individual variables, even the least correct variable, weight, is at around 90%. Figure A.2: Data correctness at variable level Regarding the thresholds used in the rule-based cleaning algorithm, these are based on the most extreme naturally occurring events - the beekeeper inspections. In the below chart, weight drops by more than 12kg per Minute when a frame is removed. At the same time, due to the entry of dry air, humidity is dropping rapidly, while the bees are also heating up under stress (the temperature sensor at the humidity unit heats up to over 50¬∞ possibly because it is exposed to direct sun). Figure A.3: Variable fluctuations during a beekeeper inspection This is a case of weight developments that cannot be reconciled with normal behaviour. Likely the sensor is not correctly calibrated (or the values belong to a different sensor). Figure A.4: Anomalous weight fluctuations The analysis of available information of incomplete data suggests that the thermometers fail more frequently during colder outside temperatures and with higher humidity. Also the last valid data point before a data gap tends to have a lower temperatures than the distribution of all valid values. Figure A.5: Humidity and missingness Figure A.6: Outside temperature and missingness Figure A.7: Valid observations vs. values before gaps Figure A.8: App menus to create apiary Figure A.9: App menus to create hive Figure A.10: App menus to record an inspection Figure A.11: Valid observations per inspection field Figure A.12: Frames changed during inspections and impact on weight Figure A.13: Availability of meteorological data near the beehives "],["references.html", "References", " References Anand, N., V. B. Raj, M. S. Ullas, and A. Srivastava. 2018. Swarm Detection and Beehive Monitoring System Using Auditory and Microclimatic Analysis. In 2018 3rd International Conference on Circuits, Control, Communication and Computing (I4c), 14. https://doi.org/10.1109/CIMCA.2018.8739710. Arnia - Remote Bee Hive Monitoring System. 5/2/2020. https://www.arnia.co.uk/. Bayir, Raif, and Ahmet Albayrak. 2016. The Monitoring of Nectar Flow Period of Honey Bees Using Wireless Sensor Networks. International Journal of Distributed Sensor Networks 12 (11): 155014771667800. https://doi.org/10.1177/1550147716678003. Beewise. 5/2/2020. https://www.beewise.ag/. BMBF-Internetredaktion. 2019. Dem Bienensterben Auf Der Spur - BMBF. https://www.bmbf.de/de/dem-bienensterben-auf-der-spur-9156.html. . 2019. Dem Bienensterben Auf Der Spur - BMBF. https://www.bmbf.de/de/dem-bienensterben-auf-der-spur-9156.html. Bme280. 5/7/2020. https://www.bosch-sensortec.com/products/environmental-sensors/humidity-sensors-bme280/. Boessenkool, Berry. 2020. Rdwd: Select and Download Climate Data from DWD (German Weather Service). https://CRAN.R-project.org/package=rdwd. Breiman, Leo. 2001. Random Forests. Machine Learning 45 (1): 532. https://doi.org/10.1023/A:1010933404324. Breiman, Leo, Jerome Friedman, Charles J. Stone, and R. A. Olshen. 1998. Classification and Regression Trees. Repr. Boca Raton: Chapman &amp; Hall. Chawla, N. V., K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. 2002. SMOTE: Synthetic Minority over-Sampling Technique. Journal of Artificial Intelligence Research 16: 32157. https://doi.org/10.1613/jair.953. Cheng, Hongju, Danyang Feng, Xiaobin Shi, and Chongcheng Chen. 2018. Data Quality Analysis and Cleaning Strategy for Wireless Sensor Networks. EURASIP Journal on Wireless Communications and Networking 2018 (1). https://doi.org/10.1186/s13638-018-1069-6. Cleveland, Robert. B., William S. Cleveland, Jean E. McRae, and Irma Terpenning. 1990. STL : A Seasonal-Trend Decomposition Procedure Based on Loess. Journal of Office Statistics 6 (1): 373. https://ci.nii.ac.jp/naid/10014960531/. CorrelAid. 4/1/2020. https://correlaid.org/. Davidson, Padraig, Michael Steininger, Florian Lautenschlager, Konstantin Kobs, Anna Krause, and Andreas Hotho. 2020. Anomaly Detection in Beehives Using Deep Recurrent Autoencoders. Proceedings of the 9th International Conference on Sensor Networks (SENSORNETS. https://arxiv.org/pdf/2003.04576. Deutscher Imkerbund. 2020. Weniger Winterverluste Als Erwartet. https://deutscherimkerbund.de/download/0-603. Dineva, Kristina, and Tatiana Atanasova. 2018. ICT-Based Beekeeping Using IoT and Machine Learning. In Developments in Language Theory, edited by Mizuho Hoshi and Shinnosuke Seki, 11088:13243. Lecture Notes in Computer Science. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-99447-512. Doull, Keith M. 1976. The Effects of Different Humidities on the Hatching of the Eggs of Honeybees. Apidologie 7 (1): 6166. https://www.semanticscholar.org/paper/THE-EFFECTS-OF-DIFFERENT-HUMIDITIES-ON-THE-HATCHING-Doull/89eefe19fd0706f8648d7e4ea23a84aacef64ec9. Ds18s20 1-Wire Parasite-Power Digital Thermometer. 5/9/2020. https://www.maximintegrated.com/en/products/sensors/DS18S20.html. Edwards Murphy, Fiona, Michele Magno, Liam OLeary, Killian Troy, P√°draig M. Whelan, and Emanuel M. Popovici. 2015. Big Brother for Bees (3b)  Energy Neutral Platform for Remote Monitoring of Beehive Imagery and Sound. In 2015 6th International Workshop on Advances in Sensors and Interfaces (IWASI), 10611. https://doi.org/10.1109/IWASI.2015.7184943. Edwards Murphy, Fiona, Michele Magno, Padraig Whelan, and Emanuel Popo Vici. 2015. B+WSN: Smart Beehive for Agriculture, Environmental, and Honey Bee Health Monitoring  Preliminary Results and Analysis. In 2015 IEEE Sensors Applications Symposium (SAS), 16. IEEE. https://doi.org/10.1109/SAS.2015.7133587. Edwards-Murphy, Fiona, Michele Magno, P√°draig M. Whelan, John OHalloran, and Emanuel M. Popovici. 2016. B+WSN: Smart Beehive with Preliminary Decision Tree Analysis for Agriculture and Honey Bee Health Monitoring. Computers and Electronics in Agriculture 124: 21119. https://doi.org/10.1016/j.compag.2016.04.008. Estrella, Arturo, and Gikas A. Hardouvelis. 1991. The Term Structure as a Predictor of Real Economic Activity. The Journal of Finance 46 (2): 55576. http://www.jstor.org/stable/2328836. Filonov, Pavel, Andrey Lavrentyev, and Artem Vorontsov. 2016. Multivariate Industrial Time Series with Cyber-Attack Simulation: Fault Detection Using an LSTM-Based Predictive Data Model. https://arxiv.org/pdf/1612.06676. Friedman, Jerome H. 2001. Greedy Function Approximation: A Gradient Boosting Machine. The Annals of Statistics 29 (5): 11891232. https://doi.org/10.1214/aos/1013203451. Genersch, Elke, Werner von der Ohe, Hannes Kaatz, Annette Schroeder, Christoph Otten, Ralph B√ºchler, Stefan Berg, et al. 2010. The German Bee Monitoring Project: A Long Term Study to Understand Periodically High Winter Losses of Honey Bee Colonies. Apidologie 41 (3): 33252. https://doi.org/10.1051/apido/2010014. Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT Press. Hiverize. 5/16/2020. Einbau Der Temperatursensoren. https://hiverize.org/einbautemperatursensor/. Human, Hannelie, Sue W. Nicolson, and Vincent Dietemann. 2006. Do Honeybees, Apis Mellifera Scutellata, Regulate Humidity in Their Nest? Die Naturwissenschaften 93 (8): 397401. https://doi.org/10.1007/s00114-006-0117-y. InfluxData. 3/3/2020. InfluxDB Open Source Time Series Database. https://www.influxdata.com/products/influxdb-overview/. Innovative Beehive Monitoring System by Pollenity. 4/22/2020. https://pollenity.com/. James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2017. An Introduction to Statistical Learning: With Applications in r. Corrected at 8th printing. Springer Texts in Statistics. New York; Heidelberg; Dordrecht; London: Springer. Kaiser, W., and J. Steiner-Kaiser. 1983. Neuronal Correlates of Sleep, Wakefulness and Arousal in a Diurnal Insect. Nature 301 (5902): 7079. https://doi.org/10.1038/301707a0. Klein, Alexandra-Maria, Bernard E. Vaissi√®re, James H. Cane, Ingolf Steffan-Dewenter, Saul A. Cunningham, Claire Kremen, and Teja Tscharntke. 2007. Importance of Pollinators in Changing Landscapes for World Crops. Proceedings of the Royal Society B: Biological Sciences 274 (1608): 30313. https://doi.org/10.1098/rspb.2006.3721. Klockgether, Fred, and Peter Hefner. 2016. Faktencheck Bienen. https://www.iva.de/sites/default/files/benutzer/. Kuhn, Max, and Kjell Johnson. 2019. Feature Engineering and Selection: A Practical Approach for Predictive Models. Chapman &amp; Hall/CRC Data Science Series. CRC Press. https://books.google.de/books?id=q5alDwAAQBAJ. Malhotra, Pankaj, Vishnu TV, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet Agarwal, and Gautam Shroff. 2016. Multi-Sensor Prognostics Using an Unsupervised Health Index Based on LSTM Encoder-Decoder. https://arxiv.org/pdf/1608.06154. Markovic, Dusan, Uros Pesovic, Sladjana Djurasevic, and Sinisa Randjic. 2016. Decision Support System for Temperature Monitoring in Beehives. 0354-9542 21 (42): 13544. https://doi.org/10.5937/AASer1642135M. Meidel, Marian. 9/4/2020. Offenbach: Diebesbanden Klauen Bienenv√∂lker Im Fr√ºhling  Immer Wieder. Op-Online.de, 9/4/2020. https://www.op-online.de/offenbach/offenbach-diebesbanden-klauen-bienenvoelker-immer-wieder-zr-13645987.html. Moritz, Steffen, and Thomas Bartz-Beielstein. 2017. imputeTS: Time Series Missing Value Imputation in r. The R Journal 9 (1): 20718. https://doi.org/10.32614/RJ-2017-009. Pflanzen f√ºr Best√§uber. n.d. http://www.pan-germany.org/download/biodiversitaet/pflanzen_fuer_bestaeuber.pdf. Pycom. 28.09.2020. Fipy - Pycom. https://pycom.io/product/fipy/. Rosenkranz, Peter, Pia Aumeier, and Bettina Ziegelmann. 2010. Biology and Control of Varroa Destructor. Journal of Invertebrate Pathology 103 Suppl 1: S96119. https://doi.org/10.1016/j.jip.2009.07.016. Senger, Diren, Carolin Johannsen, Alexandros Melemenidis, Alexander Goncharskiy, and Thorsten Kluss. 2020. Unsupervised Anomaly Detection on Multisensory Data from Honey Bee Colonies. In 2020 IEEE International Conference on Data Mining (ICDM). Sensorbeuten - Cognitive Neuroinformatics. 5/2/2020. http://www.cognitive-neuroinformatics.com/de/forschung/projekte/sensorbeuten. Single Point Load Cell H40a. 5/3/2020. https://www.bosche.eu/en/scale-components/load-cells/single-point-load-cell/single-point-load-cell-h40a. Solutionbee. 5/2/2020. https://solutionbee.com/. The Hiveeyes Developers. 10/2/2019. The Hiveeyes Project. https://hiveeyes.org/. . 10/2/2019. The Hiveeyes Project. https://hiveeyes.org/. Thieurmel, Benoit, and Achraf Elmarhraoui. 2019. Suncalc: Compute Sun Position, Sunlight Phases, Moon Position and Lunar. https://CRAN.R-project.org/package=suncalc. Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy DAgostino McGowan, Romain Fran√ßois, Garrett Grolemund, et al. 2019. Welcome to the tidyverse. Journal of Open Source Software 4 (43). https://doi.org/10.21105/joss.01686. Wikipedia, ed. 2020. Western Honey Bee. https://en.wikipedia.org/w/index.php?title=Western_honey_bee&amp;oldid=953816884. Worlds Best Smart Beehive Monitoring System - Gobuzzr. 5/2/2020. https://www.gobuzzr.com/. Wright, Marvin N., and Andreas Ziegler. 2017. Ranger: A Fast Implementation of Random Forests for High Dimensional Data in c++ and r. Journal of Statistical Software 77 (1): 117. https://doi.org/10.18637/jss.v077.i01. Zacepins, Aleksejs, Valters Brusbardis, Jurijs Meitalovs, and Egils Stalidzans. 2015. Challenges in the Development of Precision Beekeeping. Biosystems Engineering 130: 6071. https://doi.org/10.1016/j.biosystemseng.2014.12.001. Zacepins, Aleksejs, Armands Kviesis, Egils Stalidzans, Marta Liepniece, and Jurijs Meitalovs. 2016. Remote Detection of the Swarming of Honey Bee Colonies by Single-Point Temperature Monitoring. Biosystems Engineering 148: 7680. https://doi.org/10.1016/j.biosystemseng.2016.05.012. Ziegler, Silvio, Martin Dettli, and Jonas Thommen. 2019. Ein Neuer Blickwinkel Aufs Schwarmgeschehen. Schweizerische Bienen-Zeitung 2019 (2): 2226. "]]
